---
title: GPUで使用したoptimizerをsave & load する時の注意
tags:
  - DeepLearning
  - PyTorch
private: false
updated_at: '2020-02-11T00:37:38+09:00'
id: 00eea382015c9d13911f
organization_url_name: null
slide: false
ignorePublish: false
---
#ブログ概況
- PyTorchの学習を別ジョブに引き継ぐ場合における注意点として、modelのweightだけでなく、optimizerやschedulerなどもsave & loadする必要があります。
- optimizerについては特に注意が必要だと感じていて、うっかり前の情報を引き継がずにoptimizerを初期化して学習開始してしまった場合、モデルを引き継いだのにも関わらす、急に精度が落ちてしまうこともあります。
- OptimizerのLoad & Saveについて、デバイスを意識していないと、学習時に思わぬエラーを吐いてしまっていたので、その対処法の紹介。

#代表的な２つの最適化アルゴリズム
 （一応、OptimizerをLoadする必要性の簡単な説明から書いていますが、結論から先に知りたいって方は、このブログの[GPU環境で使用したOptimizerを再度GPU環境で学習する際の注意点](#gpu環境で使用したoptimizerを再度gpu環境で学習する際の注意点)に対処法を記述しています。）

##SGD
　確率的勾配降下法と呼ばれるものです。計算される勾配情報（損失関数の一階微分）を元に新たなweightに更新されます。式で表すと以下の形です。

```math
\mathbf{w}^{t + 1} \gets \mathbf{w}^{t} - \eta \frac{\partial E(\mathbf{w}^{t})}{\partial \mathbf{w}^{t}}
```

見ての通り、学習率は勾配や前回のweight更新量などに関係せず一定です。なのでSGDに関してはoptimizerのsave&loadに関して、特に気をつける必要はありません。

##Adam
　Adam(Adaptive moment estimation)はAdaGradやRMSProp、AdaDeltaを改良したものです。
以下の式のようにweightを更新していきます。

```math
m_{t+1} = \beta_{1} m_{t} + (1 - \beta_{1}) \nabla E(\mathbf{w}^{t}) \ \ \ \cdots\ \ \ (1)\\
v_{t+1} = \beta_{2} v_{t} + (1 - \beta_{2}) \nabla E(\mathbf{w}^{t})^{2} \ \ \ \cdots\ \ \ (2)\\
\hat{m} = \frac{m_{t+1}}{1 - \beta_{1}^{t}}\\
\hat{v} = \frac{v_{t+1}}{1 - \beta_{2}^{t}}\\
\mathbf{w}^{t+1} \gets \mathbf{w}^{t} - \alpha \frac{\hat{m}}{\sqrt{\hat{v}} + \epsilon}
```

初期値は$m_0=0$、$\nu_0=0$となっています。またハイパーパラメータの推奨値は以下の通りです。

```math
\alpha=0.001\\
\beta_{1}=0.9\\
\beta_{2}=0.999\\
\epsilon=10^{−8}\\
```

(1)式をみて分かる通り、Adamは更新前の勾配が式に組み込まれることで、結果的に勾配の移動平均を取っています。また(2)式をみて分かる通り、勾配の二乗の移動平均も式に組み込まれています。
　結果的に前回の勾配情報を元に学習率を逐次調整しながらtraingが進んでいくので、SGDと違い学習率は一定にならないというわけです。

#PyTorchでのsave
　ここからは実際に、PyTorchでのOptimizerのセーブやロードを見ていきます。まずはデモ用に簡単なモデルクラスやoptimizerをインスタンス化していきます。尚、下記コードはPyTorchの[公式リファレンス](https://pytorch.org/tutorials/beginner/saving_loading_models.html)を参考に一部追記・削除しています。

```python
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau


class SampleModel(nn.Module):
    def __init__(self):
        super(SampleModel, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

model = SampleModel()
optimizer = optim.Adam(model.parameters(), lr=1e-3)
scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=5)
```

- PyTorchのmodelクラスに存在する学習可能なweightは`model.parameters()`でアクセス可能です。
- 各レイヤーとmodelのモデルのweightをマッピングするオブジェクトを`state_dict()`メソッドで生成可能です。非常に便利！
- 試しにmodelとoptimizerに`state_dict()`メソッドを適用してみます。

```python
print('lr: ', optimizer.state_dict()['param_groups'][0]['lr'])
print('betas: ', optimizer.state_dict()['param_groups'][0]['betas'])
print('eps: ', optimizer.state_dict()['param_groups'][0]['eps'])
print('weight_decay: ', optimizer.state_dict()['param_groups'][0]['weight_decay'])
print('amsgrad: ', optimizer.state_dict()['param_groups'][0]['amsgrad'])
print('params: ', optimizer.state_dict()['param_groups'][0]['params'])

print("\nModel's state_dict:")
for param_tensor in model.state_dict():
    print(param_tensor, "\t", model.state_dict()[param_tensor].size())
```

```text:Out
lr:  0.001
betas:  (0.9, 0.999)
eps:  1e-08
weight_decay:  0
amsgrad:  False
params:  [140713907680744, 140713907680888, 140713907680960, 140713907681032, 140713907681104, 140713907681176, 140713907681248, 140713907681320, 140713907681392, 140713907681464]

Model's state_dict:
conv1.weight 	 torch.Size([6, 3, 5, 5])
conv1.bias 	 torch.Size([6])
conv2.weight 	 torch.Size([16, 6, 5, 5])
conv2.bias 	 torch.Size([16])
fc1.weight 	 torch.Size([120, 400])
fc1.bias 	 torch.Size([120])
fc2.weight 	 torch.Size([84, 120])
fc2.bias 	 torch.Size([84])
fc3.weight 	 torch.Size([10, 84])
fc3.bias 	 torch.Size([10])
```

これらを保存、ロードすることで学習&推論が可能となっています。保存とロードは以下のように行います。

```python
import torch

# save
torch.save(model.state_dict(), PATH1)
torch.save(optimizer.state_dict(), PATH2)

# initialize
model = SampleModel()
optimizer = optim.Adam(model.parameters(), lr=1e-3)

# load
model.load_state_dict(torch.load(PATH1))
optimizer.load_state_dict(torch.load(PATH2))
```

あるいは下記のようにまとめてシリアル化することも可能です。こちらの方が小分けにする必要がないのでバグに繋がりにくいです。

```python
state = {
    'model': model.state_dict(),
    'optimizer': optimizer.state_dict(),
}

torch.save(state, PATH3)

# initialize
model = SampleModel()
optimizer = optim.Adam(model.parameters(), lr=1e-3)

# load
checkpoint = torch.load(PATH3)
model.load_state_dict(checkpoint['model'])
optimizer.load_state_dict(checkpoint['optimizer'])
```

#GPU環境で使用したOptimizerを再度GPU環境で学習する際の注意点
　というわけでいざ学習を再開しようとすると、学習中にエラーが発生。メッセージを見てみると、どうやら`torch.FloatTensor`と`torch.cuda.FloatTensor`で整合性が取れてないようです。

```text:ErrorMessage
RuntimeError: expected device cpu but got device cuda:0
```

　[Loading a saved model for continue training](https://discuss.pytorch.org/t/loading-a-saved-model-for-continue-training/17244/2)でも議論されているのですが、どうやら継続してoptimizerを使用する場合、以下の様に逐一`.cuda()`をしないといけません。

```python
for state in optimizer.state.values():
    for k, v in state.items():
        if isinstance(v, torch.Tensor):
            state[k] = v.to('cuda')
```

　結構、初期の頃にハマりがちなポイントだと思うので、改めてブログ記事にさせて頂きました。
